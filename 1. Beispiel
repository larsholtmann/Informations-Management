# Import der wichtigsten Datenpakete

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Datensatz laden
df = pd.read_csv("heart_disease_uci.csv")

# Spaltennamen bereinigen (falls nötig)
df.columns = df.columns.str.strip()

# Features und Zielvariable definieren
X = df.drop("num", axis=1)  # Alle Features außer der Diagnose werden als Features definiert, Diagnose ist die Zielvariable (wollen wir voraussagen)
y = (df["num"] > 0).astype(int)  # Zielvariable: 0 = gesund, 1 = Krankheit

# Kategorische Daten umwandeln mit dummies
X = pd.get_dummies(X)  # Wandelt Textspalten in Zahlen um

# Trainings- und Testdaten aufteilen
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Modell erstellen und trainieren
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Vorhersagen treffen
y_pred = model.predict(X_test)

# Genauigkeit des Modells berechnen und darstellen
accuracy = accuracy_score(y_test, y_pred)
print(f"Modellgenauigkeit: {accuracy:.2f}")
from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_test, y_pred))
importances = model.feature_importances_
feature_names = X.columns
important_features = sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)


print("Wichtigste Features:", important_features[:10])
# Import des Seaborn Paketes zur besseren und schöneren Darstellung
import matplotlib.pyplot as plt
import seaborn as sns

# Darstellung der Wichtigkeit von Merkmalen mittels Seaborn Paket
top_features = pd.DataFrame(important_features[:10], columns=["Feature", "Importance"])
sns.barplot(x="Importance", y="Feature", data=top_features)
plt.title("Top 10 wichtigste Features")
plt.show()
